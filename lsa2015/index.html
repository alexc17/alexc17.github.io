<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">
<html>
<head>
          
  <meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1">
                     
  <meta name="description" content="lsa 2015 chicago alex clark course learning context free languages context free grammatical inference.">
  <title>Learnability and Language Acquisition</title>
   <link rel="stylesheet" type="text/css" href="../alex.css">
</head>
 <body bgcolor="#fffffe">
<center>
<h1>Distributional Learning of Syntax</h1>
<h2>A course at LSA Summer Institute, Chicago, July 2015</h2>
</center>

<h2>Lecturer</h2>

<p>Alexander Clark, King's College London.</p>

<h2>Course Overview</h2>
<p>
This course will look at the computational and mathematical theory of how grammars can be learned from strings.  
Any theory of language acquisition must at bottom rest on some
solution to this problem.
</p>
<p>
In the last ten years there has been very rapid progress in this field
using what is called distributional learning; we will cover a family
of techniques for learning context free grammars and richer formalisms
equivalent to Minimalist Grammars.
We will review empirical work using naturally occurring corpora, but the primary goal is to understand the fundamental principles that underly this problem.
</p>

<h2>Slides and Materials</h2>

<p> Course material; the lecture slides will be put up after each lecture.</p>


<h3> Lecture 1 </h3>

The first lecture will be a general introduction and we will look at a
specific learning algorithm for substitutable context-free grammars,
and relate this to the general problem of language acquisition.
<ul>
<li> Materials </li>
<li> Slides <a href="lecture1actual.pdf">lecture1actual.pdf</a>
</li>
<li> Readings: <a
href="ClarkEyraud2007JMLR.pdf">Clark and Eyraud (2007)</a>

<a href="Berwick et al 2011.pdf">Berwick et al 2011.pdf</a>
 </li>

  </ul>

 
<h3> Lecture 2 </h3>

This lecture will look at the weak learning of a larger class of context free grammars.
We will consider learning models where the learner can use queries,
  and related this to the use of probabilistic data.

  <ul>
<li> Homework: please email me something by Sunday evening.
<a href="homework1.pdf">homework1.pdf</a>.
    Here are some <a href="homework1model.pdf">Model answers</a>.
    </li>
<li> Slides <a href="lecture2.pdf">lecture2 slides</a>
</li>
<li> Readings: please have a look at this before Monday's lecture (Lecture 3):
<a href="mcfgsforlinguists.pdf">mcfgsforlinguists.pdf</a>
 </li>
  </ul>
  
<h3> Lecture 3 </h3>

We will look at learning grammars beyond context-free; in particular
  at learning Multiple Context-Free Grammars which are equivalent to
  Stabler's Minimalist grammars. We will also look at learning
  copying.
  <ul>
<li> Slides <a href="lecture3.pdf">lecture3 slides</a>
  </ul>
<h3> Lecture 4 </h3>

  We will look at strong learning &mdash; learning syntactic structure
  &mdash;  and how this relates more generally to the problem of
  learning semantics. This will be the moment to discuss the relation
  of these distributional learning ideas to syntactic and semantic
  bootstrapping and more generally to linguistic theory.

 <ul>
   <li> Slides <a href="lecture4.pdf">lecture4 slides</a>
<li> Homework: please email me something by Saturday lunchtime.
<a href="homework2.pdf">homework2.pdf</a>.
   <ul>


<p> Alexander Clark <a href="mailto:alexsclark@gmail.com">alexsclark@gmail.com</a></p><a href="homework1.pdf">homework1.pdf</a>


<p> <a href="../index.html">Home</a>.</p>
</body>
</html>
